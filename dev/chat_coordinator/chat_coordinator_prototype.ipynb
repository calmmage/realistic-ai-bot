{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "414c5f8bcb08569a",
   "metadata": {},
   "source": [
    "\n",
    "# Part 1 - Chat Coordinator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pydantic import BaseModel\n",
    "from apscheduler.schedulers.asyncio import AsyncIOScheduler\n",
    "from enum import Enum\n",
    "from typing import List, Callable\n",
    "class ChatCoordinatorBase:\n",
    "    pass\n",
    "\n",
    "class EventType(Enum):\n",
    "    HANDLE_INPUT_MESSAGE = \"handle_input_message\"\n",
    "    HANDLE_OUTPUT_MESSAGE = \"handle_output_message\"\n",
    "\n",
    "# class Event(BaseModel):\n",
    "#     event_type: EventType\n",
    "\n",
    "class InputMessage(BaseModel):\n",
    "    message: str\n",
    "    timestamp: datetime\n",
    "\n",
    "class OutputMessage(BaseModel):\n",
    "    message: str\n",
    "    timestamp: datetime\n",
    "\n",
    "\n",
    "class ChatCoordinator(ChatCoordinatorBase):\n",
    "    input_buffer = 5 # seconds\n",
    "\n",
    "    def __init__(self, output_callback: Callable[[str], None]):\n",
    "        self.input_messages = [] # input, timestamp\n",
    "        # self.output_messages = []\n",
    "        self.events_log = []\n",
    "\n",
    "        self.scheduler = AsyncIOScheduler()\n",
    "\n",
    "        self.output_callback = output_callback\n",
    "\n",
    "    def _add_input_message(self, message: InputMessage):\n",
    "        # todo: add proper multi-user support\n",
    "        self.input_messages.append(message)\n",
    "    \n",
    "    def _clean_input_messages(self):\n",
    "        # remove all input messages\n",
    "        # todo: add proper multi-user support\n",
    "        self.input_messages = []\n",
    "\n",
    "    def add_input_message(self, message: str):\n",
    "        timestamp = datetime.now()\n",
    "        self._add_input_message(InputMessage(message=message, timestamp=timestamp))\n",
    "\n",
    "        # schedule event to handle input message\n",
    "        self.scheduler.add_job(\n",
    "            self.handle_input_message,\n",
    "            'date',\n",
    "            kwargs={'message': message},\n",
    "            run_date=datetime.now() + timedelta(seconds=self.input_buffer)\n",
    "        )\n",
    "\n",
    "\n",
    "    # region: event processors\n",
    "    def _check_new_messages_arrived(self, timestamp: datetime):\n",
    "        # check if new input messages arrived after the original one.\n",
    "        for message in self.input_messages:\n",
    "            if message.timestamp > timestamp:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _process_messages(self, messages: List[InputMessage]) -> List[OutputMessage]:\n",
    "        \n",
    "        # for now - mock response\n",
    "        # return [OutputMessage(message=\"Hello, how can I help you today?\", timestamp=datetime.now())]\n",
    "        responses = []\n",
    "        target_timestamp = datetime.now() + timedelta(seconds=1)\n",
    "        responses.append(OutputMessage(message=\"I see {len(messages)} messages from you\", timestamp=target_timestamp))\n",
    "\n",
    "        if len(messages) > 5:\n",
    "            target_timestamp = datetime.now() + timedelta(seconds=2)\n",
    "            responses.append(OutputMessage(message=\"That's a lot!\", timestamp=target_timestamp))\n",
    "\n",
    "        return responses\n",
    "\n",
    "\n",
    "    def handle_input_message(self, message: InputMessage):\n",
    "        # step 1: check if new input messages arrived after the original one.\n",
    "        if self._check_new_messages_arrived(message.timestamp):\n",
    "            return\n",
    "\n",
    "        to_process = self.input_messages\n",
    "        self._clean_input_messages()\n",
    "        responses = self._process_messages(to_process)\n",
    "        for response in responses:\n",
    "            self.scheduler.add_job(\n",
    "                self.handle_output_message,\n",
    "                'date',\n",
    "                kwargs={'message': response.message},\n",
    "                run_date=response.timestamp\n",
    "            )\n",
    "\n",
    "    def handle_output_message(self, message: str):\n",
    "        # todo: check if new input messages arrived between now and then. If yes - cancel and allow to respond again.\n",
    "        # todo: behavior 1 - stop responding\n",
    "        # todo: behavior 2 - still respond, no matter what. \n",
    "        # decide the behavior\n",
    "        #  - ask ai what to do\n",
    "        #  - randomly decide\n",
    "        #  - depending on the amount of planned response messages. If like 10 messages are queued - worth interrupting for sure..\n",
    "        #  - activate 'answer' instead of 'respond' aiogram mode.\n",
    "        self.output_callback(message)\n",
    "\n",
    "    def run(self):\n",
    "        self.scheduler.start()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7664ac81d3088538",
   "metadata": {},
   "source": [
    "# Part 2 - App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ede689852df9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppBase:\n",
    "    pass\n",
    "\n",
    "class App(AppBase):\n",
    "    def __init__(self, output_callback: Callable[[str], None]):\n",
    "        self.chat_coordinator = ChatCoordinator(output_callback)\n",
    "\n",
    "    def new_message(self, message: str):\n",
    "        self.chat_coordinator.add_input_message(message)\n",
    "\n",
    "    def run(self):\n",
    "        self.chat_coordinator.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94441c70058525c",
   "metadata": {},
   "source": [
    "# Part 3 - frontend, chat emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44392098a8aa3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    app = App(output_callback=print)\n",
    "    app.run()\n",
    "    while True:\n",
    "        user_input = input()\n",
    "        if user_input == \"exit\":\n",
    "            return\n",
    "        else:\n",
    "            print(\">\", user_input)\n",
    "            app.new_message(user_input)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af4c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
